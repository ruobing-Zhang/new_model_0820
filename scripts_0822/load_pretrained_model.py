#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶æŸ¥çœ‹å…¶ç»“æ„å’Œå‚æ•°
"""

import os
import sys
import torch
import nemo.collections.asr as nemo_asr
from omegaconf import OmegaConf

def print_model_structure(model, model_name="æ¨¡å‹"):
    """
    æ‰“å°æ¨¡å‹ç»“æ„å’Œå‚æ•°ä¿¡æ¯
    """
    print(f"\n=== {model_name} è¯¦ç»†ä¿¡æ¯ ===")
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"\nğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
    print(f"  æ¨¡å‹ç±»å‹: {type(model).__name__}")
    print(f"  è®¾å¤‡: {next(model.parameters()).device}")
    print(f"  æ•°æ®ç±»å‹: {next(model.parameters()).dtype}")
    
    # å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nğŸ“Š å‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°æ•°: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  å†»ç»“å‚æ•°: {total_params - trainable_params:,}")
    
    # æ¨¡å‹é…ç½®
    if hasattr(model, 'cfg'):
        print(f"\nâš™ï¸ æ¨¡å‹é…ç½®:")
        print(f"  é…ç½®ç±»å‹: {type(model.cfg).__name__}")
        
        # é¢„å¤„ç†å™¨ä¿¡æ¯
        if hasattr(model, 'preprocessor') and model.preprocessor is not None:
            print(f"\nğŸ”§ é¢„å¤„ç†å™¨ ({type(model.preprocessor).__name__}):")
            preprocessor = model.preprocessor
            
            # å°è¯•è·å–å„ç§å±æ€§
            attrs_to_check = ['sample_rate', 'n_mels', 'n_fft', 'win_length', 'hop_length', 
                            'window_size', 'window_stride', 'features']
            for attr in attrs_to_check:
                if hasattr(preprocessor, attr):
                    value = getattr(preprocessor, attr)
                    print(f"    {attr}: {value}")
                elif hasattr(preprocessor, '_cfg') and hasattr(preprocessor._cfg, attr):
                    value = getattr(preprocessor._cfg, attr)
                    print(f"    {attr}: {value}")
        
        # ç¼–ç å™¨ä¿¡æ¯
        if hasattr(model, 'encoder') and model.encoder is not None:
            print(f"\nğŸ§  ç¼–ç å™¨ ({type(model.encoder).__name__}):")
            encoder = model.encoder
            
            # å°è¯•è·å–å„ç§å±æ€§
            attrs_to_check = ['d_model', 'n_heads', 'num_layers', 'n_layers', 'feat_in', 
                            'feat_out', 'subsampling_factor', 'conv_kernel_size']
            for attr in attrs_to_check:
                if hasattr(encoder, attr):
                    value = getattr(encoder, attr)
                    print(f"    {attr}: {value}")
                elif hasattr(encoder, '_cfg') and hasattr(encoder._cfg, attr):
                    value = getattr(encoder._cfg, attr)
                    print(f"    {attr}: {value}")
        
        # è§£ç å™¨ä¿¡æ¯
        if hasattr(model, 'decoder') and model.decoder is not None:
            print(f"\nğŸ“ è§£ç å™¨ ({type(model.decoder).__name__}):")
            decoder = model.decoder
            
            attrs_to_check = ['pred_hidden', 'pred_rnn_layers', 'vocab_size']
            for attr in attrs_to_check:
                if hasattr(decoder, attr):
                    value = getattr(decoder, attr)
                    print(f"    {attr}: {value}")
                elif hasattr(decoder, '_cfg') and hasattr(decoder._cfg, attr):
                    value = getattr(decoder._cfg, attr)
                    print(f"    {attr}: {value}")
        
        # Jointç½‘ç»œä¿¡æ¯
        if hasattr(model, 'joint') and model.joint is not None:
            print(f"\nğŸ”— Jointç½‘ç»œ ({type(model.joint).__name__}):")
            joint = model.joint
            
            attrs_to_check = ['joint_hidden', 'activation']
            for attr in attrs_to_check:
                if hasattr(joint, attr):
                    value = getattr(joint, attr)
                    print(f"    {attr}: {value}")
                elif hasattr(joint, '_cfg') and hasattr(joint._cfg, attr):
                    value = getattr(joint._cfg, attr)
                    print(f"    {attr}: {value}")
        
        # Tokenizerä¿¡æ¯
        if hasattr(model, 'tokenizer') and model.tokenizer is not None:
            print(f"\nğŸ”¤ Tokenizer ({type(model.tokenizer).__name__}):")
            tokenizer = model.tokenizer
            
            if hasattr(tokenizer, 'vocab_size'):
                print(f"    è¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}")
            
            # æµ‹è¯•tokenizer
            try:
                test_text = "ä½ å¥½ä¸–ç•Œ"
                tokens = tokenizer.text_to_ids(test_text)
                decoded = tokenizer.ids_to_text(tokens)
                print(f"    æµ‹è¯•ç¼–ç  '{test_text}' -> {tokens}")
                print(f"    æµ‹è¯•è§£ç  {tokens} -> '{decoded}'")
            except Exception as e:
                print(f"    Tokenizeræµ‹è¯•å¤±è´¥: {e}")
    
    # æ¨¡å—å‚æ•°åˆ†å¸ƒ
    print(f"\nğŸ“ˆ å„æ¨¡å—å‚æ•°åˆ†å¸ƒ:")
    module_params = {}
    for name, module in model.named_children():
        params = sum(p.numel() for p in module.parameters())
        if params > 0:
            module_params[name] = params
            print(f"    {name}: {params:,} å‚æ•°")
    
    # æ¨¡å‹çŠ¶æ€
    print(f"\nğŸ” æ¨¡å‹çŠ¶æ€:")
    print(f"    è®­ç»ƒæ¨¡å¼: {model.training}")
    
    return total_params, trainable_params

def main():
    """
    ä¸»å‡½æ•°ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶æŸ¥çœ‹ç»“æ„
    """
    print("å¼€å§‹åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
    
    # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    model_path = "/root/autodl-tmp/joint_sortformer_and_asr_0815/pretrained_models/stt_zh_conformer_transducer_large.nemo"
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return False
        
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
        
        # åŠ è½½æ¨¡å‹
        print("\nğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        model = nemo_asr.models.EncDecRNNTModel.restore_from(model_path, map_location='cpu')
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        
        # æ‰“å°æ¨¡å‹ç»“æ„å’Œå‚æ•°
        total_params, trainable_params = print_model_structure(model, "é¢„è®­ç»ƒRNNTæ¨¡å‹")
        
        # æ‰“å°å®Œæ•´é…ç½®ï¼ˆå¯é€‰ï¼‰
        print("\n" + "="*50)
        print("ğŸ“‹ å®Œæ•´æ¨¡å‹é…ç½®:")
        print("="*50)
        if hasattr(model, 'cfg'):
            print(OmegaConf.to_yaml(model.cfg))
        
        return True
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… æ¨¡å‹åŠ è½½å’Œåˆ†æå®Œæˆï¼")
    else:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼")
        sys.exit(1)