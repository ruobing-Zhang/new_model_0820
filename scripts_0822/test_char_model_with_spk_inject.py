#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è„šæœ¬ï¼šåˆå§‹åŒ–å­—ç¬¦çº§RNNTæ¨¡å‹ï¼ˆå¸¦è¯´è¯äººæ³¨å…¥å’ŒAdapterï¼‰ï¼Œ
åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå¹¶æ‰“å°æ¨¡å‹ç»“æ„å’Œå‚æ•°ä¿¡æ¯ã€‚
"""

import os
import sys
import torch
import torch.nn as nn
from omegaconf import OmegaConf

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rnnt_char_model_with_spk_inject import RNNTCharWithSpkInject, RNNTCharWithSpkInjectAndAdapter
from rnnt_models import EncDecRNNTModel


def load_pretrained_model(model_path):
    """
    åŠ è½½é¢„è®­ç»ƒçš„.nemoæ¨¡å‹
    
    Args:
        model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        
    Returns:
        åŠ è½½çš„æ¨¡å‹å®ä¾‹
    """
    print(f"æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    # ä½¿ç”¨NeMoçš„restore_fromæ–¹æ³•åŠ è½½æ¨¡å‹
    try:
        base_model = EncDecRNNTModel.restore_from(model_path)
        print(f"æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œç±»å‹: {type(base_model)}")
        return base_model
    except Exception as e:
        print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¤±è´¥: {e}")
        raise


def print_model_info(model, model_name="æ¨¡å‹"):
    """
    æ‰“å°æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯
    
    Args:
        model: æ¨¡å‹å®ä¾‹
        model_name: æ¨¡å‹åç§°
    """
    print(f"\n{'='*60}")
    print(f"{model_name} è¯¦ç»†ä¿¡æ¯")
    print(f"{'='*60}")
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"æ¨¡å‹ç±»å‹: {type(model).__name__}")
    print(f"è®¾å¤‡: {next(model.parameters()).device}")
    print(f"æ•°æ®ç±»å‹: {next(model.parameters()).dtype}")
    
    # è®¡ç®—å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nå‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°æ•°: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}")
    print(f"  å†»ç»“å‚æ•°æ•°: {total_params - trainable_params:,}")
    
    # æ¨¡å‹ç»“æ„
    print(f"\næ¨¡å‹ç»“æ„:")
    
    # é¢„å¤„ç†å™¨ä¿¡æ¯
    if hasattr(model, 'preprocessor'):
        preprocessor = model.preprocessor
        print(f"  é¢„å¤„ç†å™¨: {type(preprocessor).__name__}")
        if hasattr(preprocessor, 'n_mels'):
            print(f"    Melé¢‘è°±ç»´åº¦: {preprocessor.n_mels}")
        if hasattr(preprocessor, 'sample_rate'):
            print(f"    é‡‡æ ·ç‡: {preprocessor.sample_rate}")
    
    # ç¼–ç å™¨ä¿¡æ¯
    if hasattr(model, 'encoder'):
        encoder = model.encoder
        print(f"  ç¼–ç å™¨: {type(encoder).__name__}")
        if hasattr(encoder, 'd_model'):
            print(f"    éšè—ç»´åº¦: {encoder.d_model}")
        if hasattr(encoder, 'n_layers') or hasattr(encoder, 'num_layers'):
            n_layers = getattr(encoder, 'n_layers', getattr(encoder, 'num_layers', 'Unknown'))
            print(f"    å±‚æ•°: {n_layers}")
        if hasattr(encoder, 'n_heads'):
            print(f"    æ³¨æ„åŠ›å¤´æ•°: {encoder.n_heads}")
    
    # è§£ç å™¨ä¿¡æ¯
    if hasattr(model, 'decoder'):
        decoder = model.decoder
        print(f"  è§£ç å™¨: {type(decoder).__name__}")
        if hasattr(decoder, 'pred_hidden'):
            print(f"    é¢„æµ‹éšè—ç»´åº¦: {decoder.pred_hidden}")
        if hasattr(decoder, 'pred_rnn_layers'):
            print(f"    RNNå±‚æ•°: {decoder.pred_rnn_layers}")
    
    # Jointç½‘ç»œä¿¡æ¯
    if hasattr(model, 'joint'):
        joint = model.joint
        print(f"  Jointç½‘ç»œ: {type(joint).__name__}")
        if hasattr(joint, 'num_classes'):
            print(f"    è¾“å‡ºç±»åˆ«æ•°: {joint.num_classes}")
        if hasattr(joint, 'vocabulary') and joint.vocabulary:
            print(f"    è¯æ±‡è¡¨å¤§å°: {len(joint.vocabulary)}")
    
    # è¯´è¯äººæ³¨å…¥ç›¸å…³ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if hasattr(model, 'K_max'):
        print(f"\nè¯´è¯äººæ³¨å…¥ä¿¡æ¯:")
        print(f"  æœ€å¤§è¯´è¯äººæ•°: {model.K_max}")
        print(f"  ç¼–ç å™¨éšç»´: {model.M}")
        if hasattr(model, 'alpha'):
            print(f"  æ³¨å…¥å¼ºåº¦: {model.alpha.item():.4f}")
        if hasattr(model, 'Gamma'):
            print(f"  æ­£å¼¦æ ¸å½¢çŠ¶: {model.Gamma.shape}")
    
    # Adapterä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if hasattr(model, 'adapters'):
        print(f"\nAdapterä¿¡æ¯:")
        print(f"  Adapteræ•°é‡: {len(model.adapters)}")
        if hasattr(model, 'adapter_bottleneck'):
            print(f"  ç“¶é¢ˆç»´åº¦: {model.adapter_bottleneck}")
        
        # è®¡ç®—Adapterå‚æ•°æ•°é‡
        adapter_params = sum(p.numel() for adapter in model.adapters for p in adapter.parameters())
        print(f"  Adapterå‚æ•°æ•°: {adapter_params:,}")
    
    # é…ç½®ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if hasattr(model, 'cfg'):
        print(f"\né…ç½®ä¿¡æ¯:")
        if hasattr(model.cfg, 'labels'):
            print(f"  å­—ç¬¦æ ‡ç­¾æ•°é‡: {len(model.cfg.labels)}")
            print(f"  å‰10ä¸ªå­—ç¬¦: {model.cfg.labels[:10]}")
    
    print(f"{'='*60}\n")


def load_weights_with_mismatch_handling(target_model, source_model, strict=False):
    """
    åŠ è½½æƒé‡ï¼Œå¤„ç†å½¢çŠ¶ä¸åŒ¹é…çš„æƒ…å†µï¼ˆå¦‚Adapterå±‚ï¼‰
    
    Args:
        target_model: ç›®æ ‡æ¨¡å‹
        source_model: æºæ¨¡å‹
        strict: æ˜¯å¦ä¸¥æ ¼åŒ¹é…æ‰€æœ‰å‚æ•°
    """
    print("\nå¼€å§‹åŠ è½½æƒé‡...")
    
    source_state_dict = source_model.state_dict()
    target_state_dict = target_model.state_dict()
    
    loaded_keys = []
    missing_keys = []
    unexpected_keys = []
    size_mismatch_keys = []
    
    for key in target_state_dict.keys():
        if key in source_state_dict:
            source_param = source_state_dict[key]
            target_param = target_state_dict[key]
            
            if source_param.shape == target_param.shape:
                target_state_dict[key] = source_param
                loaded_keys.append(key)
            else:
                size_mismatch_keys.append((key, source_param.shape, target_param.shape))
        else:
            missing_keys.append(key)
    
    for key in source_state_dict.keys():
        if key not in target_state_dict:
            unexpected_keys.append(key)
    
    # åŠ è½½åŒ¹é…çš„æƒé‡
    target_model.load_state_dict(target_state_dict, strict=False)
    
    # æ‰“å°åŠ è½½ç»“æœ
    print(f"\næƒé‡åŠ è½½ç»“æœ:")
    print(f"  æˆåŠŸåŠ è½½: {len(loaded_keys)} ä¸ªå‚æ•°")
    print(f"  ç¼ºå¤±å‚æ•°: {len(missing_keys)} ä¸ª")
    print(f"  å¤šä½™å‚æ•°: {len(unexpected_keys)} ä¸ª")
    print(f"  å½¢çŠ¶ä¸åŒ¹é…: {len(size_mismatch_keys)} ä¸ª")
    
    if missing_keys:
        print(f"\nç¼ºå¤±çš„å‚æ•°ï¼ˆé€šå¸¸æ˜¯æ–°å¢çš„Adapterå’Œè¯´è¯äººæ³¨å…¥å‚æ•°ï¼‰:")
        for key in missing_keys[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"    {key}")
        if len(missing_keys) > 10:
            print(f"    ... è¿˜æœ‰ {len(missing_keys) - 10} ä¸ª")
    
    if size_mismatch_keys:
        print(f"\nå½¢çŠ¶ä¸åŒ¹é…çš„å‚æ•°:")
        for key, source_shape, target_shape in size_mismatch_keys:
            print(f"    {key}: {source_shape} -> {target_shape}")
    
    return len(loaded_keys), len(missing_keys)


def test_model_with_real_audio(model, manifest_path):
    """
    ä½¿ç”¨manifestæ–‡ä»¶ä¸­çš„çœŸå®éŸ³é¢‘æ•°æ®æµ‹è¯•æ¨¡å‹æ¨ç†
    """
    import json
    import librosa
    import numpy as np
    
    try:
        # è¯»å–manifestæ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼‰
        data = []
        with open(manifest_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data.append(json.loads(line.strip()))
        
        print(f"Manifestæ–‡ä»¶åŒ…å« {len(data)} æ¡æ•°æ®")
        
        # å–ç¬¬ä¸€æ¡æ•°æ®è¿›è¡Œæµ‹è¯•
        sample = data[0]
        audio_path = sample['audio_filepath']
        text = sample['text']
        pgt_path = sample.get('pgt_npy', '')
        
        print(f"\næµ‹è¯•æ•°æ®ä¿¡æ¯:")
        print(f"  éŸ³é¢‘è·¯å¾„: {audio_path}")
        print(f"  å‚è€ƒæ–‡æœ¬: {text}")
        print(f"  PGTæ–‡ä»¶è·¯å¾„: {pgt_path}")
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_path):
            print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return
        
        # åŠ è½½éŸ³é¢‘
        audio, sr = librosa.load(audio_path, sr=16000)
        print(f"\néŸ³é¢‘ä¿¡æ¯:")
        print(f"  éŸ³é¢‘é•¿åº¦: {len(audio)/sr:.2f}ç§’")
        print(f"  é‡‡æ ·ç‡: {sr}Hz")
        print(f"  éŸ³é¢‘å½¢çŠ¶: {audio.shape}")
        
        # åŠ è½½PGTæ–‡ä»¶ï¼ˆè¯´è¯äººæ¦‚ç‡ï¼‰
        pgt_data = None
        if pgt_path and os.path.exists(pgt_path):
            pgt_data = np.load(pgt_path)  # å‡è®¾æ˜¯.npyæ–‡ä»¶
            print(f"\nPGTæ•°æ®ä¿¡æ¯:")
            print(f"  PGTå½¢çŠ¶: {pgt_data.shape}")
            print(f"  PGTæ•°æ®ç±»å‹: {pgt_data.dtype}")
            print(f"  PGTæ•°å€¼èŒƒå›´: [{pgt_data.min():.4f}, {pgt_data.max():.4f}]")
        else:
            print(f"\nâš ï¸ PGTæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„ä¸ºç©º: {pgt_path}")
            # åˆ›å»ºè™šæ‹Ÿçš„è¯´è¯äººæ ‡ç­¾ç”¨äºæµ‹è¯•
            # å‡è®¾4ä¸ªè¯´è¯äººï¼Œæ—¶é—´æ­¥é•¿åº¦ä¸ºéŸ³é¢‘é•¿åº¦çš„1/160ï¼ˆå¯¹åº”16kHzéŸ³é¢‘çš„å¸§ç‡ï¼‰
            time_steps = len(audio) // 160
            pgt_data = np.random.rand(4, time_steps).astype(np.float32)
            print(f"  ä½¿ç”¨è™šæ‹ŸPGTæ•°æ®ï¼Œå½¢çŠ¶: {pgt_data.shape}")
        
        # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        audio_tensor = torch.tensor(audio).unsqueeze(0).float()  # [1, T]
        audio_length = torch.tensor([len(audio)])
        
        # å‡†å¤‡è¯´è¯äººæ ‡ç­¾ - è½¬æ¢PGTæ•°æ®æ ¼å¼
        if pgt_data is not None:
            # PGTæ•°æ®é€šå¸¸æ˜¯ [K, T] æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º [B, K, T]
            spk_labels = torch.tensor(pgt_data).unsqueeze(0).float()  # [1, K, T]
            print(f"\nè¯´è¯äººæ ‡ç­¾å½¢çŠ¶: {spk_labels.shape}")
            
            # è®¾ç½®è¯´è¯äººæ ‡ç­¾
            if hasattr(model, 'set_speaker_labels'):
                model.set_speaker_labels(spk_labels)
                print(f"âœ… å·²è®¾ç½®è¯´è¯äººæ ‡ç­¾")
        
        print(f"\næ¨¡å‹è¾“å…¥å‡†å¤‡å®Œæˆ:")
        print(f"  éŸ³é¢‘å¼ é‡å½¢çŠ¶: {audio_tensor.shape}")
        print(f"  éŸ³é¢‘é•¿åº¦: {audio_length}")
        if pgt_data is not None:
            print(f"  è¯´è¯äººæ ‡ç­¾å½¢çŠ¶: {spk_labels.shape}")
        
        print("\nå¼€å§‹æ¨¡å‹æ¨ç†...")
        with torch.no_grad():
            try:
                # æµ‹è¯•é¢„å¤„ç†å™¨
                if hasattr(model, 'preprocessor'):
                    processed_signal, processed_length = model.preprocessor(
                        input_signal=audio_tensor,
                        length=audio_length
                    )
                    print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œç‰¹å¾å½¢çŠ¶: {processed_signal.shape}")
                
                # æµ‹è¯•ç¼–ç å™¨ï¼ˆå¸¦è¯´è¯äººæ³¨å…¥ï¼‰
                if hasattr(model, 'encode_with_injection') and pgt_data is not None:
                    encoded, encoded_len = model.encode_with_injection(
                        audio_tensor, audio_length, spk_labels
                    )
                    print(f"âœ… ç¼–ç å™¨ï¼ˆå¸¦è¯´è¯äººæ³¨å…¥ï¼‰å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {encoded.shape}")
                elif hasattr(model, 'encoder'):
                    encoded, encoded_len = model.encoder(
                        audio_signal=processed_signal,
                        length=processed_length
                    )
                    print(f"âœ… ç¼–ç å™¨å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {encoded.shape}")
                
                # æµ‹è¯•è§£ç å™¨ï¼ˆå¯é€‰ï¼‰
                if hasattr(model, 'decoder'):
                    try:
                        # åˆ›å»ºç®€å•çš„ç›®æ ‡åºåˆ—ç”¨äºæµ‹è¯•
                        dummy_targets = torch.zeros(1, 10, dtype=torch.long)  # [B, T]
                        dummy_target_length = torch.tensor([10])
                        
                        decoder_output = model.decoder(
                            targets=dummy_targets,
                            target_length=dummy_target_length
                        )
                        
                        # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
                        if isinstance(decoder_output, tuple):
                            if len(decoder_output) == 2:
                                pred_out, pred_len = decoder_output
                                print(f"âœ… è§£ç å™¨æµ‹è¯•å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {pred_out.shape}")
                            else:
                                print(f"âœ… è§£ç å™¨æµ‹è¯•å®Œæˆï¼Œè¿”å›äº† {len(decoder_output)} ä¸ªè¾“å‡º")
                                print(f"  ç¬¬ä¸€ä¸ªè¾“å‡ºå½¢çŠ¶: {decoder_output[0].shape}")
                        else:
                            print(f"âœ… è§£ç å™¨æµ‹è¯•å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {decoder_output.shape}")
                    except Exception as decoder_e:
                        print(f"âš ï¸ è§£ç å™¨æµ‹è¯•è·³è¿‡: {str(decoder_e)}")
                
                print("\nğŸ‰ å®Œæ•´æ¨¡å‹æ¨ç†æµ‹è¯•æˆåŠŸï¼")
                
            except Exception as e:
                print(f"âŒ æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                import traceback
                traceback.print_exc()
        
    except Exception as e:
        print(f"âŒ çœŸå®éŸ³é¢‘æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


def main():
    """
    ä¸»å‡½æ•°ï¼šæµ‹è¯•å­—ç¬¦çº§RNNTæ¨¡å‹çš„åˆå§‹åŒ–å’Œæƒé‡åŠ è½½
    """
    print("å¼€å§‹æµ‹è¯•å­—ç¬¦çº§RNNTæ¨¡å‹ï¼ˆå¸¦è¯´è¯äººæ³¨å…¥å’ŒAdapterï¼‰")
    
    # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    pretrained_model_path = "/root/autodl-tmp/joint_sortformer_and_asr_0815/pretrained_models/stt_zh_conformer_transducer_large.nemo"
    
    try:
        # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        print("\næ­¥éª¤1: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
        base_model = load_pretrained_model(pretrained_model_path)
        print_model_info(base_model, "é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹")
        
        # 2. å‡†å¤‡é…ç½®
        print("\næ­¥éª¤2: å‡†å¤‡æ¨¡å‹é…ç½®")
        cfg = base_model.cfg.copy()
        # ç§»é™¤æ•°æ®é…ç½®ä»¥é¿å…åˆå§‹åŒ–æ—¶çš„æ•°æ®è·¯å¾„é—®é¢˜
        if 'train_ds' in cfg:
            del cfg.train_ds
        if 'validation_ds' in cfg:
            del cfg.validation_ds
        if 'test_ds' in cfg:
            del cfg.test_ds
        
        # 3. åˆ›å»ºå¸¦è¯´è¯äººæ³¨å…¥çš„æ¨¡å‹ï¼ˆä¸å¸¦Adapterï¼‰
        print("\næ­¥éª¤3: åˆ›å»ºå¸¦è¯´è¯äººæ³¨å…¥çš„å­—ç¬¦çº§RNNTæ¨¡å‹")
        spk_inject_model = RNNTCharWithSpkInject(
            cfg=cfg,
            trainer=None,
            K_max=4,
            alpha_init=0.1,
            base_model=None  # ä¸ä¼ å…¥base_modelï¼Œé¿å…é‡å¤åˆå§‹åŒ–
        )
        print_model_info(spk_inject_model, "è¯´è¯äººæ³¨å…¥æ¨¡å‹")
        
        # 4. åˆ›å»ºå¸¦Adapterçš„æ¨¡å‹
        print("\næ­¥éª¤4: åˆ›å»ºå¸¦è¯´è¯äººæ³¨å…¥å’ŒAdapterçš„å­—ç¬¦çº§RNNTæ¨¡å‹")
        full_model = RNNTCharWithSpkInjectAndAdapter(
            cfg=cfg,
            trainer=None,
            K_max=4,
            alpha_init=0.1,
            base_model=None,  # ä¸ä¼ å…¥base_modelï¼Œé¿å…é‡å¤åˆå§‹åŒ–
            num_adapters=12,
            adapter_bottleneck=256
        )
        print_model_info(full_model, "å®Œæ•´æ¨¡å‹ï¼ˆè¯´è¯äººæ³¨å…¥+Adapterï¼‰")
        
        # 5. æµ‹è¯•æƒé‡åŠ è½½
        print("\næ­¥éª¤5: æµ‹è¯•æƒé‡åŠ è½½")
        loaded_count, missing_count = load_weights_with_mismatch_handling(full_model, base_model)
        
        print(f"\næƒé‡åŠ è½½å®Œæˆ:")
        print(f"  æˆåŠŸåŠ è½½ {loaded_count} ä¸ªå‚æ•°")
        
        print(f"  æ–°å¢å‚æ•° {missing_count} ä¸ªï¼ˆAdapterå’Œè¯´è¯äººæ³¨å…¥ç›¸å…³ï¼‰")
        
        # 5. æµ‹è¯•ä½¿ç”¨çœŸå®éŸ³é¢‘æ•°æ®è¿›è¡Œæ¨ç†
        print("\næ­¥éª¤5: ä½¿ç”¨çœŸå®éŸ³é¢‘æ•°æ®æµ‹è¯•æ¨¡å‹åŠŸèƒ½")
        manifest_path = "/root/autodl-tmp/joint_sortformer_and_asr_0815/scripts_0822/M8013_multispeaker_manifest_train_joint_no_punc_with_4speakers.json"
        test_model_with_real_audio(full_model, manifest_path)
        
        # 6. æµ‹è¯•å‚æ•°å†»ç»“åŠŸèƒ½
        print("\næ­¥éª¤6: æµ‹è¯•å‚æ•°å†»ç»“åŠŸèƒ½")
        full_model.freeze_base_model()
        
        trainable_params_after_freeze = sum(p.numel() for p in full_model.parameters() if p.requires_grad)
        print(f"å†»ç»“åå¯è®­ç»ƒå‚æ•°æ•°: {trainable_params_after_freeze:,}")
        
        # è§£å†»
        full_model.unfreeze_all()
        trainable_params_after_unfreeze = sum(p.numel() for p in full_model.parameters() if p.requires_grad)
        print(f"è§£å†»åå¯è®­ç»ƒå‚æ•°æ•°: {trainable_params_after_unfreeze:,}")
        
        print("\næµ‹è¯•å®Œæˆï¼æ¨¡å‹åˆå§‹åŒ–å’Œæƒé‡åŠ è½½æˆåŠŸã€‚")
        
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)