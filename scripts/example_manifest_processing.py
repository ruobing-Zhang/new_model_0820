#!/usr/bin/env python3
"""
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¿®æ”¹åçš„auto_align_speaker_labels.pyè„šæœ¬
é€šè¿‡å®é™…æ¨ç†å¤„ç†åŒ…å«RTTMè·¯å¾„çš„manifestæ–‡ä»¶

è¯¥ç¤ºä¾‹å±•ç¤ºäº†æ–°çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä»manifestæ–‡ä»¶ä¸­è¯»å–éŸ³é¢‘å’ŒRTTMæ–‡ä»¶è·¯å¾„
2. ä½¿ç”¨é¢„è®­ç»ƒASRæ¨¡å‹å¯¹éŸ³é¢‘è¿›è¡Œå®é™…æ¨ç†
3. è·å–çœŸå®çš„ç¼–ç å™¨æ—¶é—´ç»´åº¦ï¼ˆè€Œéè®¡ç®—å¾—å‡ºï¼‰
4. å°†RTTMè½¬æ¢ä¸ºä¸ç¼–ç å™¨è¾“å‡ºç²¾ç¡®å¯¹é½çš„è¯´è¯äººæ ‡ç­¾çŸ©é˜µ
"""

import os
import json
import numpy as np
from pathlib import Path

# å¯¼å…¥æˆ‘ä»¬çš„è‡ªåŠ¨å¯¹é½å·¥å…·
from auto_align_speaker_labels import RTTMToNPYConverter, BatchProcessor

def create_example_manifest_with_rttm():
    """
    åˆ›å»ºä¸€ä¸ªåŒ…å«éŸ³é¢‘å’ŒRTTMè·¯å¾„çš„ç¤ºä¾‹manifestæ–‡ä»¶
    """
    print("\n" + "="*60)
    print("åˆ›å»ºç¤ºä¾‹manifestæ–‡ä»¶ï¼ˆåŒ…å«RTTMè·¯å¾„ï¼‰")
    print("="*60)
    
    # åˆ›å»ºç¤ºä¾‹ç›®å½•ç»“æ„
    base_dir = Path("/tmp/example_dataset")
    audio_dir = base_dir / "audio"
    rttm_dir = base_dir / "rttm"
    
    audio_dir.mkdir(parents=True, exist_ok=True)
    rttm_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶ï¼ˆç©ºæ–‡ä»¶ï¼Œä»…ç”¨äºæ¼”ç¤ºï¼‰
    audio_files = [
        "conversation_001.wav",
        "conversation_002.wav", 
        "conversation_003.wav"
    ]
    
    for audio_file in audio_files:
        audio_path = audio_dir / audio_file
        # åˆ›å»ºä¸€ä¸ªå°çš„ç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶ï¼ˆ1ç§’çš„é™éŸ³ï¼‰
        import torchaudio
        # åˆ›å»º1ç§’16kHzçš„é™éŸ³éŸ³é¢‘
        waveform = torch.zeros(1, 16000)  # 1é€šé“ï¼Œ16000é‡‡æ ·ç‚¹
        torchaudio.save(str(audio_path), waveform, 16000)
    
    # åˆ›å»ºå¯¹åº”çš„RTTMæ–‡ä»¶
    rttm_contents = [
        # conversation_001.rttm - ä¸¤ä¸ªè¯´è¯äºº
        "SPEAKER conversation_001 1 0.0 2.5 <NA> <NA> speaker_0 <NA> <NA>\n" +
        "SPEAKER conversation_001 1 2.5 3.0 <NA> <NA> speaker_1 <NA> <NA>\n" +
        "SPEAKER conversation_001 1 5.5 2.0 <NA> <NA> speaker_0 <NA> <NA>\n",
        
        # conversation_002.rttm - ä¸‰ä¸ªè¯´è¯äºº
        "SPEAKER conversation_002 1 0.0 1.8 <NA> <NA> speaker_0 <NA> <NA>\n" +
        "SPEAKER conversation_002 1 1.8 2.2 <NA> <NA> speaker_1 <NA> <NA>\n" +
        "SPEAKER conversation_002 1 4.0 1.5 <NA> <NA> speaker_2 <NA> <NA>\n" +
        "SPEAKER conversation_002 1 5.5 1.0 <NA> <NA> speaker_0 <NA> <NA>\n",
        
        # conversation_003.rttm - å•ä¸ªè¯´è¯äºº
        "SPEAKER conversation_003 1 0.0 4.0 <NA> <NA> speaker_0 <NA> <NA>\n" +
        "SPEAKER conversation_003 1 4.5 2.5 <NA> <NA> speaker_0 <NA> <NA>\n"
    ]
    
    for i, (audio_file, rttm_content) in enumerate(zip(audio_files, rttm_contents)):
        rttm_file = audio_file.replace('.wav', '.rttm')
        rttm_path = rttm_dir / rttm_file
        with open(rttm_path, 'w') as f:
            f.write(rttm_content)
    
    # åˆ›å»ºåŒ…å«RTTMè·¯å¾„çš„manifestæ–‡ä»¶
    manifest_data = []
    for audio_file in audio_files:
        audio_path = str(audio_dir / audio_file)
        rttm_file = audio_file.replace('.wav', '.rttm')
        rttm_path = str(rttm_dir / rttm_file)
        
        manifest_entry = {
            "audio_filepath": audio_path,
            "rttm_filepath": rttm_path,  # æ–°å¢ï¼šRTTMæ–‡ä»¶è·¯å¾„
            "duration": 8.0,  # ç¤ºä¾‹æ—¶é•¿
            "text": f"Example conversation {audio_file}"
        }
        manifest_data.append(manifest_entry)
    
    # ä¿å­˜manifestæ–‡ä»¶
    manifest_path = base_dir / "train_manifest_with_rttm.json"
    with open(manifest_path, 'w') as f:
        for entry in manifest_data:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')
    
    print(f"âœ… åˆ›å»ºäº†ç¤ºä¾‹æ•°æ®é›†:")
    print(f"   éŸ³é¢‘ç›®å½•: {audio_dir}")
    print(f"   RTTMç›®å½•: {rttm_dir}")
    print(f"   Manifestæ–‡ä»¶: {manifest_path}")
    print(f"   åŒ…å« {len(manifest_data)} ä¸ªæ¡ç›®")
    
    return str(manifest_path), str(base_dir)

def demonstrate_single_file_inference():
    """
    æ¼”ç¤ºå•æ–‡ä»¶æ¨ç†æ¨¡å¼ï¼šé€šè¿‡å®é™…æ¨ç†è·å–ç¼–ç å™¨æ—¶é—´ç»´åº¦
    """
    print("\n" + "="*60)
    print("æ¼”ç¤ºå•æ–‡ä»¶æ¨ç†æ¨¡å¼")
    print("="*60)
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¸€ä¸ªçœŸå®çš„ASRæ¨¡å‹è·¯å¾„
    # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œè¯·æ›¿æ¢ä¸ºæ‚¨çš„ASRæ¨¡å‹è·¯å¾„
    asr_model_path = "/path/to/your/asr_model.nemo"  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    
    print("\nâš ï¸  æ³¨æ„ï¼šæ­¤æ¼”ç¤ºéœ€è¦çœŸå®çš„ASRæ¨¡å‹")
    print(f"è¯·å°† asr_model_path è®¾ç½®ä¸ºæ‚¨çš„ASRæ¨¡å‹è·¯å¾„")
    print(f"å½“å‰è®¾ç½®: {asr_model_path}")
    
    if not os.path.exists(asr_model_path):
        print("\nâŒ ASRæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å®é™…æ¨ç†æ¼”ç¤º")
        print("\nğŸ’¡ å¦‚æœæ‚¨æœ‰ASRæ¨¡å‹ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
        print("1. å°† asr_model_path è®¾ç½®ä¸ºæ‚¨çš„æ¨¡å‹è·¯å¾„")
        print("2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return
    
    # å¦‚æœæ¨¡å‹å­˜åœ¨ï¼Œæ‰§è¡Œå®é™…æ¨ç†
    try:
        converter = RTTMToNPYConverter(asr_model_path)
        
        # ä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶
        audio_path = "/tmp/example_dataset/audio/conversation_001.wav"
        rttm_path = "/tmp/example_dataset/rttm/conversation_001.rttm"
        output_path = "/tmp/example_dataset/conversation_001_aligned.npy"
        speaker_ids = ["speaker_0", "speaker_1"]
        
        print(f"\nğŸ”„ æ­£åœ¨å¤„ç†: {Path(audio_path).name}")
        
        # æ‰§è¡Œè½¬æ¢ï¼ˆé€šè¿‡å®é™…æ¨ç†ï¼‰
        conversion_info = converter.convert_rttm_to_npy(
            rttm_path, audio_path, output_path, speaker_ids
        )
        
        print("\nâœ… è½¬æ¢å®Œæˆï¼")
        print(f"ğŸ“Š è½¬æ¢ä¿¡æ¯:")
        for key, value in conversion_info.items():
            print(f"   {key}: {value}")
        
        # åŠ è½½å¹¶æ£€æŸ¥ç”Ÿæˆçš„çŸ©é˜µ
        speaker_matrix = np.load(output_path)
        print(f"\nğŸ“ˆ ç”Ÿæˆçš„è¯´è¯äººçŸ©é˜µ:")
        print(f"   å½¢çŠ¶: {speaker_matrix.shape}")
        print(f"   æ•°æ®ç±»å‹: {speaker_matrix.dtype}")
        print(f"   å€¼èŒƒå›´: [{speaker_matrix.min():.3f}, {speaker_matrix.max():.3f}]")
        
    except Exception as e:
        print(f"\nâŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ASRæ¨¡å‹è·¯å¾„å’Œä¾èµ–é¡¹")

def demonstrate_batch_processing_from_manifest():
    """
    æ¼”ç¤ºä»manifestæ–‡ä»¶æ‰¹é‡å¤„ç†ï¼šæ–°çš„æ¨èæ–¹æ³•
    """
    print("\n" + "="*60)
    print("æ¼”ç¤ºä»manifestæ–‡ä»¶æ‰¹é‡å¤„ç†ï¼ˆæ¨èæ–¹æ³•ï¼‰")
    print("="*60)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    manifest_path, base_dir = create_example_manifest_with_rttm()
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    output_npy_dir = os.path.join(base_dir, "aligned_speaker_labels")
    output_manifest_path = os.path.join(base_dir, "train_manifest_with_aligned_labels.json")
    
    # è¯´è¯äººIDåˆ—è¡¨
    speaker_ids = ["speaker_0", "speaker_1", "speaker_2"]
    
    print(f"\nğŸ“‹ å¤„ç†å‚æ•°:")
    print(f"   è¾“å…¥manifest: {manifest_path}")
    print(f"   è¾“å‡ºNPYç›®å½•: {output_npy_dir}")
    print(f"   è¾“å‡ºmanifest: {output_manifest_path}")
    print(f"   è¯´è¯äººIDs: {speaker_ids}")
    
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦çœŸå®çš„ASRæ¨¡å‹
    asr_model_path = "/path/to/your/asr_model.nemo"  # è¯·æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    
    print(f"\nâš ï¸  æ³¨æ„ï¼šéœ€è¦çœŸå®çš„ASRæ¨¡å‹è¿›è¡Œæ¨ç†")
    print(f"å½“å‰ASRæ¨¡å‹è·¯å¾„: {asr_model_path}")
    
    if not os.path.exists(asr_model_path):
        print("\nâŒ ASRæ¨¡å‹ä¸å­˜åœ¨ï¼Œæ˜¾ç¤ºå¤„ç†æµç¨‹ï¼ˆä¸æ‰§è¡Œå®é™…æ¨ç†ï¼‰")
        print("\nğŸ’¡ å®é™…ä½¿ç”¨æ—¶çš„å‘½ä»¤è¡Œè°ƒç”¨æ–¹å¼ï¼š")
        print(f"python auto_align_speaker_labels.py batch_process_manifest \\")
        print(f"  --asr_model_path {asr_model_path} \\")
        print(f"  --manifest_path {manifest_path} \\")
        print(f"  --output_npy_dir {output_npy_dir} \\")
        print(f"  --output_manifest_path {output_manifest_path} \\")
        print(f"  --speaker_ids {' '.join(speaker_ids)} \\")
        print(f"  --rttm_field rttm_filepath")
        return
    
    # å¦‚æœæ¨¡å‹å­˜åœ¨ï¼Œæ‰§è¡Œå®é™…æ‰¹é‡å¤„ç†
    try:
        processor = BatchProcessor(asr_model_path)
        
        print("\nğŸ”„ å¼€å§‹æ‰¹é‡å¤„ç†...")
        stats = processor.process_dataset_from_manifest(
            manifest_path=manifest_path,
            output_npy_dir=output_npy_dir,
            output_manifest_path=output_manifest_path,
            speaker_ids=speaker_ids,
            rttm_field="rttm_filepath"  # manifestä¸­RTTMè·¯å¾„çš„å­—æ®µå
        )
        
        print("\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {stats}")
        
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

def explain_key_improvements():
    """
    è§£é‡Šå…³é”®æ”¹è¿›ç‚¹
    """
    print("\n" + "="*60)
    print("å…³é”®æ”¹è¿›è¯´æ˜")
    print("="*60)
    
    improvements = [
        {
            "æ ‡é¢˜": "ğŸ¯ å®é™…æ¨ç†è·å–æ—¶é—´ç»´åº¦",
            "è¯´æ˜": "ä¸å†é€šè¿‡è®¡ç®—ä¼°ç®—ç¼–ç å™¨æ—¶é—´ç»´åº¦ï¼Œè€Œæ˜¯é€šè¿‡å®é™…æ¨ç†è·å–çœŸå®çš„æ—¶é—´ç»´åº¦ï¼Œç¡®ä¿å®Œç¾å¯¹é½"
        },
        {
            "æ ‡é¢˜": "ğŸ“ æ”¯æŒmanifestä¸­çš„RTTMè·¯å¾„",
            "è¯´æ˜": "å¯ä»¥ç›´æ¥ä»manifestæ–‡ä»¶ä¸­è¯»å–RTTMæ–‡ä»¶è·¯å¾„ï¼Œæ— éœ€å•ç‹¬æŒ‡å®šRTTMç›®å½•"
        },
        {
            "æ ‡é¢˜": "ğŸ”„ æ™ºèƒ½è·¯å¾„æ¨æ–­",
            "è¯´æ˜": "å¦‚æœmanifestä¸­æ²¡æœ‰RTTMè·¯å¾„å­—æ®µï¼Œä¼šè‡ªåŠ¨ä»éŸ³é¢‘è·¯å¾„æ¨æ–­RTTMæ–‡ä»¶ä½ç½®"
        },
        {
            "æ ‡é¢˜": "ğŸ“Š è¯¦ç»†å¤„ç†ç»Ÿè®¡",
            "è¯´æ˜": "æä¾›å®Œæ•´çš„å¤„ç†ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç¼–ç å™¨æ—¶é—´ç»´åº¦åˆ†å¸ƒã€éŸ³é¢‘æ—¶é•¿ç»Ÿè®¡ç­‰"
        },
        {
            "æ ‡é¢˜": "ğŸ”§ å‘åå…¼å®¹",
            "è¯´æ˜": "ä¿ç•™åŸæœ‰çš„å¤„ç†æ–¹æ³•ï¼Œç¡®ä¿ç°æœ‰ä»£ç ä»ç„¶å¯ä»¥æ­£å¸¸å·¥ä½œ"
        }
    ]
    
    for i, improvement in enumerate(improvements, 1):
        print(f"\n{i}. {improvement['æ ‡é¢˜']}")
        print(f"   {improvement['è¯´æ˜']}")
    
    print("\n" + "="*60)
    print("æŠ€æœ¯ç»†èŠ‚")
    print("="*60)
    
    technical_details = [
        "ğŸ§  ASRç¼–ç å™¨æ¨ç†æµç¨‹ï¼šéŸ³é¢‘ â†’ é¢„å¤„ç† â†’ ç¼–ç å™¨ â†’ è·å–æ—¶é—´ç»´åº¦",
        "â±ï¸  æ—¶é—´å¯¹é½å…¬å¼ï¼šT_enc = ç¼–ç å™¨å®é™…è¾“å‡ºçš„æ—¶é—´ç»´åº¦",
        "ğŸ­ è¯´è¯äººçŸ©é˜µï¼šå½¢çŠ¶ä¸º (T_enc, num_speakers)ï¼Œæ¯ä¸ªæ—¶é—´æ­¥å¯¹åº”è¯´è¯äººæ´»åŠ¨",
        "ğŸ’¾ è¾“å‡ºæ ¼å¼ï¼šNPYæ–‡ä»¶ï¼ŒåŒ…å«float32ç±»å‹çš„è¯´è¯äººæ ‡ç­¾çŸ©é˜µ",
        "ğŸ“‹ Manifestæ›´æ–°ï¼šè‡ªåŠ¨æ·»åŠ speaker_labels_pathå­—æ®µæŒ‡å‘NPYæ–‡ä»¶"
    ]
    
    for detail in technical_details:
        print(f"   {detail}")

def main():
    """
    ä¸»æ¼”ç¤ºå‡½æ•°
    """
    print("\n" + "="*80)
    print("è‡ªåŠ¨è¯´è¯äººæ ‡ç­¾å¯¹é½å·¥å…· - å®é™…æ¨ç†ç‰ˆæœ¬æ¼”ç¤º")
    print("="*80)
    
    print("\næœ¬æ¼”ç¤ºå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¿®æ”¹åçš„auto_align_speaker_labels.pyè„šæœ¬")
    print("é€šè¿‡å®é™…ASRæ¨ç†è·å–ç¼–ç å™¨æ—¶é—´ç»´åº¦ï¼Œå®ç°ç²¾ç¡®çš„è¯´è¯äººæ ‡ç­¾å¯¹é½")
    
    # 1. è§£é‡Šå…³é”®æ”¹è¿›
    explain_key_improvements()
    
    # 2. åˆ›å»ºç¤ºä¾‹æ•°æ®å¹¶æ¼”ç¤ºmanifestå¤„ç†
    demonstrate_batch_processing_from_manifest()
    
    # 3. æ¼”ç¤ºå•æ–‡ä»¶æ¨ç†ï¼ˆå¦‚æœæœ‰æ¨¡å‹çš„è¯ï¼‰
    demonstrate_single_file_inference()
    
    print("\n" + "="*80)
    print("æ¼”ç¤ºå®Œæˆ")
    print("="*80)
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®ï¼š")
    print("1. å‡†å¤‡æ‚¨çš„ASRæ¨¡å‹æ–‡ä»¶ï¼ˆ.nemoæ ¼å¼ï¼‰")
    print("2. å‡†å¤‡åŒ…å«audio_filepathå’Œrttm_filepathçš„manifestæ–‡ä»¶")
    print("3. ä½¿ç”¨æ–°çš„batch_process_manifestæ¨¡å¼è¿›è¡Œæ‰¹é‡å¤„ç†")
    print("4. æ£€æŸ¥ç”Ÿæˆçš„å¯¹é½è¯´è¯äººæ ‡ç­¾çŸ©é˜µ")
    
    print("\nğŸ”— ç›¸å…³æ–‡ä»¶ï¼š")
    print("   - auto_align_speaker_labels.py: ä¸»è¦å¤„ç†è„šæœ¬")
    print("   - run_auto_align.sh: ä¾¿æ·çš„shellè„šæœ¬")
    print("   - README_auto_align.md: è¯¦ç»†æ–‡æ¡£")

if __name__ == "__main__":
    # æ·»åŠ å¿…è¦çš„å¯¼å…¥
    import torch
    import torchaudio
    
    main()